{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee337516",
   "metadata": {},
   "source": [
    "#### Checking the Prediction of Forward: Fine Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f505f71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at zhihan1996/DNA_bert_6 were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Constants (ensure they match your pipeline)\n",
    "MODEL_NAME = \"zhihan1996/DNA_bert_6\"\n",
    "KMER = 6\n",
    "MAX_LENGTH = 512  # Ensure same as your training\n",
    "\n",
    "# Load model/tokenizer once\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME, trust_remote_code=True).to(device)\n",
    "model.eval()\n",
    "\n",
    "def embed_single_sequence(sequence: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Embeds a single DNA sequence using the same pipeline as training.\n",
    "\n",
    "    Returns:\n",
    "        A (768,) numpy array embedding from the [CLS] token.\n",
    "    \"\"\"\n",
    "    # Apply K-mer transformation\n",
    "    sequence = sequence.upper().replace(\"N\", \"\")\n",
    "    kmers = ' '.join([sequence[i:i+KMER] for i in range(0, len(sequence) - KMER + 1)])\n",
    "\n",
    "    # Tokenize and convert to tensor\n",
    "    inputs = tokenizer(kmers, return_tensors='pt', padding='max_length', truncation=True, max_length=MAX_LENGTH)\n",
    "    input_ids = inputs[\"input_ids\"].to(device)\n",
    "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "\n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        embedding = outputs.last_hidden_state[:, 0, :]  # [CLS] token\n",
    "\n",
    "    return embedding.squeeze(0).cpu().numpy()  # shape: (768,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f28b5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved model\n",
    "import joblib\n",
    "rf_model = joblib.load(\"/home/azureuser/dna_sequencing/model_training/forw_final_randomforest_optuna_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11cec1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß¨ Sequence (Index 2530):\n",
      "TAATAAGTTAAATGTTTTGTAGTTTAAGAAATTAATTAAAATCTTAACATTGTTTTGTTTCTTAGTTATTTTGTTGGGATGTGTGGTGATGGCGCAAATG\n",
      "üî¢ Length of sequence: 100\n",
      "üß¨ Testing Sequence: TAATAAGTTAAATGTTTTGTAGTTTAAGAAATTAATTAAAATCTTAACATTGTTTTGTTTCTTAGTTATTTTGTTGGGATGTGTGGTGATGGCGCAAATG\n",
      "üî¨ Prediction: Non-Cancerous\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=7)]: Done 161 out of 161 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import glob\n",
    "\n",
    "# Path to the parquet file (adjust if needed)\n",
    "parquet_path = \"/home/azureuser/dna_sequencing/clean_forward_noncan/clean_reads_batch_65.parquet\"\n",
    "\n",
    "# Load the file\n",
    "df = pd.read_parquet(parquet_path)\n",
    "\n",
    "# Check size first to avoid IndexError\n",
    "if len(df) > 2530:\n",
    "    example_seq = df.iloc[2530]['sequence']  # 2531st row, zero-indexed\n",
    "    print(f\"üß¨ Sequence (Index 2530):\\n{example_seq}\")\n",
    "    print(f\"üî¢ Length of sequence: {len(example_seq)}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è File has only {len(df)} rows. Index 2530 is out of range.\")\n",
    "\n",
    "print(f\"üß¨ Testing Sequence: {example_seq}\")\n",
    "\n",
    "# Embed and predict\n",
    "embedding = embed_single_sequence(example_seq)\n",
    "prediction = rf_model.predict([embedding])[0]\n",
    "print(f\"üî¨ Prediction: {'Cancerous' if prediction == 1 else 'Non-Cancerous'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "733bcbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß¨ Input Sequence: TAATAAGTTAAATGTTTTGTAGTTTAAGAAATTAATTAAAATCTTAACATTGTTTTGTTTCTTAGTTATTTTGTTGGGATGTGTGGTGATGGCGCAAATG\n",
      "üî¨ Predicted Class: Non-Cancerous\n",
      "üìà Confidence: 81.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=7)]: Done 161 out of 161 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=7)]: Done 161 out of 161 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Embed the test sequence\n",
    "embedding = embed_single_sequence(example_seq)\n",
    "\n",
    "# Predict class and probability\n",
    "pred_class = rf_model.predict([embedding])[0]\n",
    "pred_proba = rf_model.predict_proba([embedding])[0]  # returns list of probabilities per class\n",
    "\n",
    "# Print results\n",
    "class_names = [\"Non-Cancerous\", \"Cancerous\"]\n",
    "predicted_label = class_names[pred_class]\n",
    "confidence = pred_proba[pred_class] * 100\n",
    "\n",
    "print(f\"üß¨ Input Sequence: {example_seq}\")\n",
    "print(f\"üî¨ Predicted Class: {predicted_label}\")\n",
    "print(f\"üìà Confidence: {confidence:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5ef657",
   "metadata": {},
   "source": [
    "#### Checking Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b48fa733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              id  label                                          embedding\n",
      "0   SRR5177930.6      1  [-0.472982, 0.902241, -0.68760836, -1.0110122,...\n",
      "1   SRR5177930.9      1  [-0.14832692, 0.1271801, -0.08398379, -1.39160...\n",
      "2  SRR5177930.11      1  [0.12253284, 1.1420611, 1.2350746, -1.3126705,...\n",
      "3  SRR5177930.16      1  [-0.28678215, 3.929915, 0.13052358, -0.0365948...\n",
      "4  SRR5177930.20      1  [-0.93153316, 0.63785285, -0.8242705, -0.75851...\n",
      "(1151263, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SRR6269879.1807337</td>\n",
       "      <td>0</td>\n",
       "      <td>[-1.0272862, -0.36884394, -1.2709365, -0.75294...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SRR5177930.18806323</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.26374084, 1.7980592, 1.2168257, -0.0639829...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRR5177930.24104586</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.43246013, 0.097811565, -0.26134557, 0.1590...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SRR5177930.52104121</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.20100069, 0.0065315273, 0.087734945, -0.161...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SRR6269879.48804038</td>\n",
       "      <td>0</td>\n",
       "      <td>[-1.1723969, 0.7453982, 0.5968736, -2.174962, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id  label  \\\n",
       "0   SRR6269879.1807337      0   \n",
       "1  SRR5177930.18806323      1   \n",
       "2  SRR5177930.24104586      1   \n",
       "3  SRR5177930.52104121      1   \n",
       "4  SRR6269879.48804038      0   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-1.0272862, -0.36884394, -1.2709365, -0.75294...  \n",
       "1  [-0.26374084, 1.7980592, 1.2168257, -0.0639829...  \n",
       "2  [-0.43246013, 0.097811565, -0.26134557, 0.1590...  \n",
       "3  [0.20100069, 0.0065315273, 0.087734945, -0.161...  \n",
       "4  [-1.1723969, 0.7453982, 0.5968736, -2.174962, ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# === Load embeddings and IDs ===\n",
    "\n",
    "# Cancerous\n",
    "emb_cancer = np.load(\"/home/azureuser/dna_sequencing/model_training/embeddings_backw_can.npy\")\n",
    "ids_cancer = pd.read_csv(\"/home/azureuser/dna_sequencing/model_training/backw_can_embeddings_ids.csv\")[\"id\"]\n",
    "labels_cancer = np.ones(len(ids_cancer), dtype=int)  # label 1\n",
    "\n",
    "# Non-cancerous\n",
    "emb_noncan = np.load(\"/home/azureuser/dna_sequencing/model_training/embeddings_backw_noncan.npy\")\n",
    "ids_noncan = pd.read_csv(\"/home/azureuser/dna_sequencing/model_training/backw_noncan_embeddings_ids.csv\")[\"id\"]\n",
    "labels_noncan = np.zeros(len(ids_noncan), dtype=int)  # label 0\n",
    "\n",
    "# === Combine all ===\n",
    "# Stack embeddings\n",
    "X = np.vstack([emb_cancer, emb_noncan])\n",
    "\n",
    "# Combine IDs and labels\n",
    "all_ids = pd.concat([ids_cancer, ids_noncan], ignore_index=True)\n",
    "all_labels = np.concatenate([labels_cancer, labels_noncan])\n",
    "\n",
    "# === Final DataFrame ===\n",
    "df_combined = pd.DataFrame({\n",
    "    \"id\": all_ids,\n",
    "    \"label\": all_labels,\n",
    "    \"embedding\": list(X)  # list of 768-d vectors per row\n",
    "})\n",
    "\n",
    "# ‚úÖ Preview\n",
    "print(df_combined.head())\n",
    "print(df_combined.shape)\n",
    "\n",
    "\n",
    "# Shuffle df\n",
    "df_combined_shuffled = df_combined.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df_combined_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4289bf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Using 8 CPU cores\n",
      "üóÇÔ∏è  Available RAM: 18.10 GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import psutil\n",
    "import os\n",
    "import joblib\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === System-aware config ===\n",
    "NUM_CORES = os.cpu_count()\n",
    "RAM_GB = psutil.virtual_memory().available / (1024 ** 3)\n",
    "\n",
    "print(f\"üß† Using {NUM_CORES} CPU cores\")\n",
    "print(f\"üóÇÔ∏è  Available RAM: {RAM_GB:.2f} GB\")\n",
    "\n",
    "# === Assume df_combined_shuffled is loaded ===\n",
    "df = df_combined_shuffled\n",
    "\n",
    "# === Convert to arrays ===\n",
    "X = np.stack(df[\"embedding\"].values).astype(np.float32)\n",
    "y = df[\"label\"].to_numpy(dtype=np.uint8)\n",
    "\n",
    "del df\n",
    "gc.collect()\n",
    "\n",
    "# === Split data ===\n",
    "split_idx = int(0.8 * len(X))\n",
    "X_train, y_train = X[:split_idx], y[:split_idx]\n",
    "X_test, y_test = X[split_idx:], y[split_idx:]\n",
    "\n",
    "del X, y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9c44dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83    109731\n",
      "           1       0.86      0.82      0.84    120522\n",
      "\n",
      "    accuracy                           0.84    230253\n",
      "   macro avg       0.84      0.84      0.84    230253\n",
      "weighted avg       0.84      0.84      0.84    230253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Load the model ‚îÄ‚îÄ‚îÄ\n",
    "model_path = \"/home/azureuser/dna_sequencing/model_training/backw_random_forest_dnabert_model.joblib\"\n",
    "model = joblib.load(model_path)\n",
    "\n",
    "# # ‚îÄ‚îÄ‚îÄ Load your test data ‚îÄ‚îÄ‚îÄ\n",
    "# # Replace with actual loading if stored in .npy or other format\n",
    "# X_test = np.load(\"X_test_forward.npy\")  # Embeddings for forward test sequences\n",
    "# y_test = np.load(\"y_test_forward.npy\")  # Ground truth labels\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Predict and evaluate ‚îÄ‚îÄ‚îÄ\n",
    "y_pred = model.predict(X_test)\n",
    "report = classification_report(y_test, y_pred, digits=2)\n",
    "\n",
    "print(\"Classification Report:\\n\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12955047",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=8)]: Done 177 out of 177 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96    109731\n",
      "           1       0.96      0.96      0.96    120522\n",
      "\n",
      "    accuracy                           0.96    230253\n",
      "   macro avg       0.96      0.96      0.96    230253\n",
      "weighted avg       0.96      0.96      0.96    230253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Load the model ‚îÄ‚îÄ‚îÄ\n",
    "model_path = \"/home/azureuser/dna_sequencing/model_training/backw_final_randomforest_optuna_model.joblib\"\n",
    "model = joblib.load(model_path)\n",
    "\n",
    "# # ‚îÄ‚îÄ‚îÄ Load your test data ‚îÄ‚îÄ‚îÄ\n",
    "# # Replace with actual loading if stored in .npy or other format\n",
    "# X_test = np.load(\"X_test_forward.npy\")  # Embeddings for forward test sequences\n",
    "# y_test = np.load(\"y_test_forward.npy\")  # Ground truth labels\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Predict and evaluate ‚îÄ‚îÄ‚îÄ\n",
    "y_pred = model.predict(X_test)\n",
    "report = classification_report(y_test, y_pred, digits=2)\n",
    "\n",
    "print(\"Classification Report:\\n\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "399fb6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[105265   4466]\n",
      " [  4351 116171]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be05c8df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dna_sequence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
